{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas por agregar\n",
    "- visualización\n",
    "- filtrado\n",
    "- incluir en loc y iloc ejemplos temporales y booleanos (ej dfl.loc['20130102':'20130104'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import importantes y cargo pickles de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "kagglehub.dataset_download(\"isathyam31/adult-income-prediction-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo pickles\n",
    "with open(\"df.pkl\",\"rb\") as file:\n",
    "    df=pickle.load(file)\n",
    "    \n",
    "with open(\"df_t.pkl\",\"rb\") as file:\n",
    "    df_t=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función más usada, lejos es `read_csv` de pandas, donde basta que demos el path del archivo y su nombre, y se leerá si no hay mayor problema. Por default, la primera fila se transforma en las columnas del dataframe, que podemos ver usando `dataframe.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/capitanespiral/Documents/GitHub/data_science\" #Aquí introducir tu path\n",
    "filename=\"data.csv\"\n",
    "\n",
    "df=pd.read_csv(f\"{path}/{filename}\")\n",
    "#Display entrega mucho mejor resultado que print para los dataframes!\n",
    "display(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Opciones más usadas de `read_csv`:\n",
    "- **sep o delimiter** &rarr; El separador de la data, usualmente se encuentra solo pero a veces es mejor darlo explícitamente. (en el caso que se confunda el identificador automático)\n",
    "- **header** &rarr; Número de fila que se toma como nombre de columnas y desde el cual comienza la data, por default, cero (inicio del .csv).\n",
    "- **skiprows** &rarr; Filas a saltar desde el inicio del archivo (indexeando desde cero, se puede entregar lista o tupla)\n",
    "- **skipfooter** &rarr; Filas a saltar desde el final del archivo.\n",
    "- **usecols** &rarr; Subset de columnas a usar (secuencia de números o nombres explícitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la primera fila está mala, cambiamos el header\n",
    "df1=pd.read_csv(\"data_bad_first_row.csv\") #Salió pésimo\n",
    "df2=pd.read_csv(\"data_bad_first_row.csv\",header=1) #Mucho mejor\n",
    "\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la segunda está mala\n",
    "df3=pd.read_csv(\"data_bad_second_row.csv\") #Primer dato pésimo\n",
    "df4=pd.read_csv(\"data_bad_second_row.csv\",skiprows=[1],header=0) #Nos saltamos la segunda fila y conservamos el header\n",
    "\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Seleccionemos ciertas columnas no más\n",
    "df5=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[0,3]) #Puede ser con números, aquí la primera y la cuarta\n",
    "df6=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=range(4)) #Puede ser con iteradores, acá me entrega de la primera A la cuarta\n",
    "df7=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[\"age\",\"education\",\"workclass\"]) #Puede ser con los nombres explícitos\n",
    "\n",
    "display(df5)\n",
    "display(df6)\n",
    "display(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df3,df4,df5,df6,df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de series de tiempo, hay que saber trabajar con `Timestamps`, `Datetime`, `Timedelta`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones generales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pd.to_datetime()** &rarr; Transforma lo que le entregues en un \"Datetime\", funciona aceptando varios formatos y si le entregas secuencias.\n",
    "- **pd.date_range()** &rarr; Para crear puntos en el tiempo equiespaceados, con un \"start\" un \"end\", posibilidad de \"periods\" o \"freq\"\n",
    "    - **freq** más comunes:\"y\" (años),\"m\" (meses),\"W\" (semana), \"B\" (business day), \"d\" (días), \"h\" (horas), \"min\" (minutos), \"s\" (segundos) Ojo que hay *infinitas* opciones! revisar en https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "- **df.resample().func()** &rarr; Entregando como variable una frecuencia, podemos \"resamplear\" según la función \"func\"\n",
    "- **datetime.min() y .max()** &rarr; Evidente\n",
    "- **datetimeindex.atributos** &rarr; nos permite acceder a muchas funciones de tiempo como \"hour\",\"day\",\"minute\",\"second\",\"dayofyear\", \"strftime\", entre otras (si es una serie, no un índice, agregar dt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datetime con varios formatos\n",
    "dt1=pd.to_datetime([\"13/1/2018\", np.datetime64(\"2018-01-13\"), datetime.datetime(2018, 1, 13)],dayfirst=True)\n",
    "print(\"dt1:\",dt1,\"\\n\")\n",
    "\n",
    "##date_range\n",
    "#Creando una lista de tiempo cada tres horas\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt2=pd.date_range(start=t1,end=t2,freq=\"3h\")\n",
    "print(\"dt2:\",dt2,\"\\n\")\n",
    "\n",
    "#Lo mismo pero con 15 minutos\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt3=pd.date_range(start=t1,end=t2,freq=\"15min\")\n",
    "print(\"dt3:\",dt3,\"\\n\")\n",
    "\n",
    "#Si tengo periodos y frecuencia\n",
    "dt4=pd.date_range(start=\"2018-8-1\", periods=5, freq=\"2d\")\n",
    "print(\"dt4:\",dt4,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como usar el resampleo\n",
    "idx = pd.date_range(\"2018-01-01\", periods=10, freq=\"h\") #ojo que 1h = h\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(\"ts\",ts,\"\\n\",sep=\"\\n\")\n",
    "#Downsample (también muy usado el sum)\n",
    "ts_downsampled=ts.resample(\"2h\").mean() #LEJOS el más útil\n",
    "print(\"ts_downsampled\",ts_downsampled,\"\\n\",sep=\"\\n\")\n",
    "#upsample (también muy usado bfill)\n",
    "ts_upsampled=ts.resample(\"30min\").ffill() #Sería interesante, acá interpolar\n",
    "print(\"ts_upsampled\",ts_upsampled,\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt1,dt2,dt3,dt4,idx,ts,ts_upsampled,ts_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajemos con data de verdad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=pd.read_csv(\"biomet1.csv\",skiprows=[1],header=0) #Tenemos caso de segunda linea sin sentido\n",
    "df_t[\"time_t\"]=pd.to_datetime(df_t['date']+\" \"+df_t['time']) #Lo guardamos en una nueva columna\n",
    "display(df_t)\n",
    "#Podemos acceder a propiedades o métodos específicos usando el \"dt\"\n",
    "print(\"Solo el año:\",df_t[\"time_t\"].dt.year,\"\\n\",sep=\"\\n\")\n",
    "print(\"Cambio el formato:\",df_t[\"time_t\"].dt.strftime(\"%Y/%m/%d\"),\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijamos un nuevo índice\n",
    "df_t=df_t.set_index(\"time_t\") #Esto elimina la columna \"time_t\"\n",
    "#Al fijarlo como índice, ahora podemos accesar simplemente con \".atributo\"\n",
    "display(df_t)\n",
    "print(df_t.index.day)\n",
    "print(df_t.index.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora cubrimos todo el espacio\n",
    "ti=df_t.index.min()\n",
    "tf=df_t.index.max()\n",
    "time_total=pd.date_range(start=ti,end=tf,freq=\"30min\")\n",
    "df_t=df_t.reindex(time_total) #Esta función redefine el índice, conservando datos y agregando nans si el nuevo índice coincide con el anterior o si no existe (para cada fila!)\n",
    "display(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamos como pickle los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El primer dataframe\n",
    "with open('df.pkl',\"wb\") as file:\n",
    "    pickle.dump(df,file)\n",
    "\n",
    "#El dataframe de serie de tiempo\n",
    "with open('df_t.pkl',\"wb\") as file:\n",
    "    pickle.dump(df_t,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See data and basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entender que *pandas* tiene dos grandes tipos de objetos: `Series`y `DataFrame`. El primero es como un \"vector\" (unidimensional) y el segundo está compuesto por varias `Series`, siendo como una \"matriz\". Y cada uno siempre tiene asociado su `Index`, que puede ser numérico o de cualquier naturaleza (uno común, temporal).\n",
    "\n",
    "La forma básica de indexar cada tipo tiene distintos resultados:\n",
    "- **Series[label]** &rarr; Dará un valor escalar en tal posición acorde al `Index`.\n",
    "- **DataFrame[colname]** &rarr; Dará una *Serie* correspondiente a tal nombre de columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accedo a una columna, me entrega a una serie, y despues a un elemento en específico\n",
    "print(\"**Dataframe**\")\n",
    "print(\"Edad\",df[\"age\"],\"\\n\",sep=\"\\n\")\n",
    "print(\"Tercer valor:\",df[\"age\"][2],\"\\n\")\n",
    "\n",
    "#Si el índice no es numérico, esto igual se puede hacer, pero se recomienda indexar acorde al índice\n",
    "print(\"**Dataframe temporal**\")\n",
    "print(\"Calor sensible\",df_t[\"H\"],\"\\n\",sep=\"\\n\") #Notar que el índice es temporal\n",
    "print(\"Tercer valor indexando con 'int':\",df_t[\"H\"][2]) #Obtengo el tercer valor -> Notar advertencia de pandas!\n",
    "print(\"Tercer valor indexando con un 'label' del 'index':\",df_t[\"H\"][\"2014-01-01 01:30:00\"]) #Lo mismo pero con el tiempo, engorroso pero preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre podemos acceder a **varios valores** de una *serie* (con indexación típica de python) o **varias columnas** en un *dataframe* (agregando un nuevo []:). Notar que esto último entrega un nuevo `DataFrame` que no permite indexación \"típica\" de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[[\"age\",\"education\"]])\n",
    "#display(df[[\"age\",\"education\"]][1:5]) #Esto tira error\n",
    "print(\"Del segundo al quinto valor de una columna:\",df[\"age\"][1:5],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También usando slices de enteros en una *serie* o *dataframe* (en este caso se accesarán filas, no columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexado clásico de python sobre una serie\n",
    "print(\"Del primer al quinto dato:\",df[\"age\"][:5],\"\\n\",sep=\"\\n\") \n",
    "print(\"Los datos pares:\",df[\"age\"][::2],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "#Indexado clásico de python sobre un dataframe\n",
    "print(\"\\nDel primer al quinto dato:\")\n",
    "display(df_t[:5]) \n",
    "print(\"\\nLos datos dados vuelta:\")\n",
    "display(df_t[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para indexar también se tienen los métodos `.loc` y `.iloc`(para *series* y *dataframes*)\n",
    "1. `.loc` &rarr; trabaja con labels del índice o con arreglos booleanos.\n",
    "2. `.iloc` &rarr; trabaja con posisiones con enteros (desde 0 a -1) o con arreglos booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df.drop([1]) #Boto la segunda fila\n",
    "display(df_temp)\n",
    "\n",
    "print(\"Con loc\",df_temp.loc[2],\"\\n\",sep=\"\\n\") #Aquí 2 es interpretado como \"label\", será la segunda fila\n",
    "\n",
    "print(\"Con loc\",df_temp.iloc[2],\"\\n\",sep=\"\\n\") #Aquí como entero, será la tercera fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando listas de elementos\n",
    "print(\"Usando listas:\")\n",
    "\n",
    "display(df_temp.loc[[0,3,5]]) #El label 0, 3, 5\n",
    "\n",
    "display(df_temp.iloc[[0,3,5]]) #Las posiciones asociados (otro label)\n",
    "\n",
    "#También usando \"slices\"\n",
    "print(\"\\nUsando slices ahora:\")\n",
    "\n",
    "display(df_temp.loc[0:5])\n",
    "\n",
    "display(df_temp.iloc[0:5])\n",
    "\n",
    "print(\"En este caso funcionan igual por la naturaleza de este índice. NOTAR que se incluye el PRINCIPIO Y EL FINAL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas loc\n",
    "print(\"Slice y columna - loc\",df_temp.loc[2:9,\"age\"],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - loc\")\n",
    "display(df_temp.loc[2:9,\"age\":\"sex\"])\n",
    "\n",
    "print(\"\\nFilas y columnas - loc\")\n",
    "display(df_temp.loc[[3,5,7],[\"age\",\"country\",\"race\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas iloc\n",
    "\n",
    "print(\"Slice y columna - iloc\",df_temp.iloc[2:9,0],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - iloc\")\n",
    "display(df_temp.iloc[2:9,0:7])\n",
    "\n",
    "print(\"\\nFilas y columnas - iloc\")\n",
    "display(df_temp.iloc[[3,5,7],[0,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una serie de funciones que nos permiten visualizar la data. Dentro de las más básicas:\n",
    "- **df.head(n)** &rarr; nos permite ver las primeras \"n\" filas (sin n, por default 5), funciona para `Series` y `DataFrame`.\n",
    "- **df.tail(n)** &rarr; nos permite ver las últimas \"n\" filas (lo mismo), funciona para `Series` y `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para dataframes\n",
    "display(df.head())\n",
    "display(df.head(10))\n",
    "\n",
    "#Para una serie\n",
    "print(df[\"age\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail())\n",
    "\n",
    "display(df[\"workclass\"].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links de interés\n",
    "- Datasets https://www.kaggle.com/datasets\n",
    "- Documentación de Pandas https://pandas.pydata.org/docs/index.html \n",
    "- Cookbook de pandas https://pandas.pydata.org/docs/user_guide/cookbook.html\n",
    "- Estructura y un par de cosas sobre data engineering https://apmonitor.com/pds/index.php/Main/DataPreparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
