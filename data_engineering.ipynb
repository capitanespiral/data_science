{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas por agregar\n",
    "- Sección de series de tiempo (datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitanespiral/Documents/GitHub/data_science/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"isathyam31/adult-income-prediction-classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función más usada, lejos es `read_csv` de pandas, donde basta que demos el path del archivo y su nombre, y se leerá si no hay mayor problema. Por default, la primera fila se transforma en las columnas del dataframe, que podemos ver usando `dataframe.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt    education  education-num  \\\n",
      "0       39          State-gov   77516    Bachelors             13   \n",
      "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
      "2       38            Private  215646      HS-grad              9   \n",
      "3       53            Private  234721         11th              7   \n",
      "4       28            Private  338409    Bachelors             13   \n",
      "...    ...                ...     ...          ...            ...   \n",
      "32556   27            Private  257302   Assoc-acdm             12   \n",
      "32557   40            Private  154374      HS-grad              9   \n",
      "32558   58            Private  151910      HS-grad              9   \n",
      "32559   22            Private  201490      HS-grad              9   \n",
      "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   White   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
      "...                    ...                 ...             ...     ...   \n",
      "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
      "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
      "32558              Widowed        Adm-clerical       Unmarried   White   \n",
      "32559        Never-married        Adm-clerical       Own-child   White   \n",
      "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week         country  \\\n",
      "0         Male          2174             0              40   United-States   \n",
      "1         Male             0             0              13   United-States   \n",
      "2         Male             0             0              40   United-States   \n",
      "3         Male             0             0              40   United-States   \n",
      "4       Female             0             0              40            Cuba   \n",
      "...        ...           ...           ...             ...             ...   \n",
      "32556   Female             0             0              38   United-States   \n",
      "32557     Male             0             0              40   United-States   \n",
      "32558   Female             0             0              40   United-States   \n",
      "32559     Male             0             0              20   United-States   \n",
      "32560   Female         15024             0              40   United-States   \n",
      "\n",
      "       salary  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "32556       0  \n",
      "32557       1  \n",
      "32558       0  \n",
      "32559       0  \n",
      "32560       1  \n",
      "\n",
      "[32561 rows x 15 columns]\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'country', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(f\"{path}/data.csv\")\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Opciones más usadas de `read_csv`:\n",
    "- **sep o delimiter** &rarr; El separador de la data, usualmente se encuentra solo pero a veces es mejor darlo explícitamente.\n",
    "- **header** &rarr; Número de fila que se toma como nombre de columnas y desde el cual comienza la data, por default, cero (inicio del .csv).\n",
    "- **skiprows** &rarr; Filas a saltar desde el inicio del archivo (indexeando desde cero, se puede entregar lista o tupla)\n",
    "- **skipfooter** &rarr; Filas a saltar desde el final del archivo.\n",
    "- **usecols** &rarr; Subset de columnas a usar (secuencia de números o nombres explícitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la primera fila está mala, cambiamos el header\n",
    "df1=pd.read_csv(f\"{path}/data_bad_first_row.csv\") #Salió pésimo\n",
    "df2=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1) #Mucho mejor\n",
    "\n",
    "#Si la segunda está mala\n",
    "df3=pd.read_csv(f\"{path}/data_bad_second_row.csv\") #Primer dato pésimo\n",
    "df4=pd.read_csv(f\"{path}/data_bad_second_row.csv\",skiprows=[1],header=0) #Nos saltamos la segunda fila y conservamos el header\n",
    "\n",
    "#Seleccionemos ciertas columnas no más\n",
    "df5=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1,usecols=[0,3]) #Puede ser con números\n",
    "df6=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1,usecols=[\"age\",\"education\",\"workclass\"]) #Puede ser con los nombres explícitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df3,df4,df5,df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de series de tiempo, hay que saber trabajar con `Timestamps`, `Datetime`, `Timedelta`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones generales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pd.to_datetime()** &rarr; Transforma lo que le entregues en un \"Datetime\", funciona aceptando varios formatos y si le entregas secuencias.\n",
    "- **pd.date_range()** &rarr; Para crear puntos en el tiempo equiespaceados, con un \"start\" un \"end\", posibilidad de \"periods\" o \"freq\"\n",
    "    - **freq** más comunes:\"y\" (años),\"m\" (meses),\"W\" (semana), \"B\" (business day), \"d\" (días), \"h\" (horas), \"min\" (minutos), \"s\" (segundos) Ojo que hay *infinitas* opciones! revisar en https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "- **df.resample().func()** &rarr; Entregando como variable una frecuencia, podemos \"resamplear\" según la función \"func\"\n",
    "- **datetime.min() y .max()** &rarr; Evidente\n",
    "- **datetimeindex.atributos** &rarr; nos permite acceder a muchas funciones de tiempo como \"hour\",\"day\",\"minute\",\"second\",\"dayofyear\", \"strftime\", entre otras (si es una serie, no un índice, agregar dt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt1: DatetimeIndex(['2018-01-13', '2018-01-13', '2018-01-13'], dtype='datetime64[ns]', freq=None)\n",
      "dt2: DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 03:00:00',\n",
      "               '2000-01-01 06:00:00', '2000-01-01 09:00:00',\n",
      "               '2000-01-01 12:00:00', '2000-01-01 15:00:00',\n",
      "               '2000-01-01 18:00:00', '2000-01-01 21:00:00',\n",
      "               '2000-01-02 00:00:00', '2000-01-02 03:00:00',\n",
      "               ...\n",
      "               '2000-10-01 21:00:00', '2000-10-02 00:00:00',\n",
      "               '2000-10-02 03:00:00', '2000-10-02 06:00:00',\n",
      "               '2000-10-02 09:00:00', '2000-10-02 12:00:00',\n",
      "               '2000-10-02 15:00:00', '2000-10-02 18:00:00',\n",
      "               '2000-10-02 21:00:00', '2000-10-03 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=2209, freq='3h')\n",
      "dt3: DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 00:15:00',\n",
      "               '2000-01-01 00:30:00', '2000-01-01 00:45:00',\n",
      "               '2000-01-01 01:00:00', '2000-01-01 01:15:00',\n",
      "               '2000-01-01 01:30:00', '2000-01-01 01:45:00',\n",
      "               '2000-01-01 02:00:00', '2000-01-01 02:15:00',\n",
      "               ...\n",
      "               '2000-10-02 21:45:00', '2000-10-02 22:00:00',\n",
      "               '2000-10-02 22:15:00', '2000-10-02 22:30:00',\n",
      "               '2000-10-02 22:45:00', '2000-10-02 23:00:00',\n",
      "               '2000-10-02 23:15:00', '2000-10-02 23:30:00',\n",
      "               '2000-10-02 23:45:00', '2000-10-03 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=26497, freq='15min')\n",
      "dt4: DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "               '2018-01-05'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "ts 2018-01-01 00:00:00    0\n",
      "2018-01-01 01:00:00    1\n",
      "2018-01-01 02:00:00    2\n",
      "2018-01-01 03:00:00    3\n",
      "2018-01-01 04:00:00    4\n",
      "2018-01-01 05:00:00    5\n",
      "2018-01-01 06:00:00    6\n",
      "2018-01-01 07:00:00    7\n",
      "2018-01-01 08:00:00    8\n",
      "2018-01-01 09:00:00    9\n",
      "Freq: h, dtype: int64\n",
      "ts_resampled 2018-01-01 00:00:00    0.5\n",
      "2018-01-01 02:00:00    2.5\n",
      "2018-01-01 04:00:00    4.5\n",
      "2018-01-01 06:00:00    6.5\n",
      "2018-01-01 08:00:00    8.5\n",
      "Freq: 2h, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-01 00:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##datetime con varios formatos\n",
    "dt1=pd.to_datetime([\"13/1/2018\", np.datetime64(\"2018-01-13\"), datetime.datetime(2018, 1, 13)],dayfirst=True)\n",
    "print(\"dt1:\",dt1)\n",
    "\n",
    "##date_range\n",
    "#Creando una lista de tiempo cada tres horas\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"10-3-2000\"\n",
    "dt2=pd.date_range(start=t1,end=t2,freq=\"3h\")\n",
    "print(\"dt2:\",dt2)\n",
    "\n",
    "#Lo mismo pero con 15 minutos\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"10-3-2000\"\n",
    "dt3=pd.date_range(start=t1,end=t2,freq=\"15min\")\n",
    "print(\"dt3:\",dt3)\n",
    "\n",
    "#Si tengo periodos y frecuencia\n",
    "dt4=pd.date_range(\"2018-01-01\", periods=5, freq=\"d\")\n",
    "print(\"dt4:\",dt4)\n",
    "\n",
    "#Como usar el resampleo\n",
    "idx = pd.date_range(\"2018-01-01\", periods=10, freq=\"h\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(\"ts\",ts)\n",
    "ts_resampled=ts.resample(\"2h\").mean()\n",
    "print(\"ts_resampled\",ts_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date      time      DOY       Ta        Pa       RH       Td  \\\n",
      "0      2014-01-01  00:30:00   1.0208  285.499  100523.0  87.5984      NaN   \n",
      "1      2014-01-01  01:00:00   1.0416  285.169  100531.0  88.4022      NaN   \n",
      "2      2014-01-01  01:30:00   1.0624  285.089  100526.0  89.6953      NaN   \n",
      "3      2014-01-01  02:00:00   1.0833  285.388  100514.0  87.9180      NaN   \n",
      "4      2014-01-01  02:30:00   1.1041  285.454  100498.0  84.4577      NaN   \n",
      "...           ...       ...      ...      ...       ...      ...      ...   \n",
      "68987  2018-02-08  21:00:00  39.8748  284.809  100917.0  87.2794  8.53473   \n",
      "68988  2018-02-08  21:30:00  39.8956  284.447  100944.0  81.5375  6.87156   \n",
      "68989  2018-02-08  22:00:00  39.9165  284.535  100961.0  77.7024  6.43326   \n",
      "68990  2018-02-08  22:30:00  39.9373  283.947  100990.0  81.4990  6.62946   \n",
      "68991  2018-02-08  23:00:00  39.9581  284.156  100990.0  78.2415  5.94753   \n",
      "\n",
      "            Tc        Rn     LWin  ...  Ts_3_1_1  SWC_1_1_1  SWC_2_1_1  \\\n",
      "0      285.499       NaN      NaN  ...   285.912   0.580774   0.677433   \n",
      "1      285.169       NaN      NaN  ...   285.869   0.581969   0.677369   \n",
      "2      285.089       NaN      NaN  ...   285.818   0.583308   0.677512   \n",
      "3      285.388       NaN      NaN  ...   285.768   0.584545   0.677424   \n",
      "4      285.454       NaN      NaN  ...   285.730   0.585552   0.677087   \n",
      "...        ...       ...      ...  ...       ...        ...        ...   \n",
      "68987  284.809 -111.9970  622.180  ...   287.100   0.269830   0.324491   \n",
      "68988  284.447  -63.4305  669.949  ...   287.074   0.270332   0.324650   \n",
      "68989  284.535  -70.1655  664.107  ...   287.047   0.270886   0.324739   \n",
      "68990  283.947  -95.6326  635.117  ...   286.994   0.271494   0.324923   \n",
      "68991  284.156  -83.2179  647.099  ...   286.938   0.272248   0.325303   \n",
      "\n",
      "       SWC_3_1_1  SHF_1_1_1  SHF_2_1_1  SHF_3_1_1         LE         H  \\\n",
      "0       0.264485   1.899400   0.491621   0.750120   0.987573   2.10820   \n",
      "1       0.264282   1.439690   0.225682   0.559402   0.167466  -4.62751   \n",
      "2       0.264079   0.982225  -0.032565   0.359773  -0.209549 -25.06920   \n",
      "3       0.263918   0.527264  -0.292637   0.154871   1.012810 -19.36180   \n",
      "4       0.264359   0.088923  -0.545190  -0.036778  -1.875870  -2.52581   \n",
      "...          ...        ...        ...        ...        ...       ...   \n",
      "68987   0.168710   1.388390   0.480249  -0.708542   0.028853 -10.19220   \n",
      "68988   0.169308   1.220350   0.355083  -1.070870  10.821500 -11.88980   \n",
      "68989   0.169821   1.017980   0.206502  -1.642580  28.889900 -46.52960   \n",
      "68990   0.170493   0.785127   0.043090  -1.978500   1.498780 -16.58690   \n",
      "68991   0.170982   0.531903  -0.125031  -2.315050  14.333400 -22.25020   \n",
      "\n",
      "                   time_t  \n",
      "0     2014-01-01 00:30:00  \n",
      "1     2014-01-01 01:00:00  \n",
      "2     2014-01-01 01:30:00  \n",
      "3     2014-01-01 02:00:00  \n",
      "4     2014-01-01 02:30:00  \n",
      "...                   ...  \n",
      "68987 2018-02-08 21:00:00  \n",
      "68988 2018-02-08 21:30:00  \n",
      "68989 2018-02-08 22:00:00  \n",
      "68990 2018-02-08 22:30:00  \n",
      "68991 2018-02-08 23:00:00  \n",
      "\n",
      "[68992 rows x 29 columns]\n",
      "0        2014\n",
      "1        2014\n",
      "2        2014\n",
      "3        2014\n",
      "4        2014\n",
      "         ... \n",
      "68987    2018\n",
      "68988    2018\n",
      "68989    2018\n",
      "68990    2018\n",
      "68991    2018\n",
      "Name: time_t, Length: 68992, dtype: int32\n",
      "0        2014/01/01\n",
      "1        2014/01/01\n",
      "2        2014/01/01\n",
      "3        2014/01/01\n",
      "4        2014/01/01\n",
      "            ...    \n",
      "68987    2018/02/08\n",
      "68988    2018/02/08\n",
      "68989    2018/02/08\n",
      "68990    2018/02/08\n",
      "68991    2018/02/08\n",
      "Name: time_t, Length: 68992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_t=pd.read_csv(\"biomet1.csv\",skiprows=[1],header=0) #Tenemos caso de segunda linea sin sentido\n",
    "df_t[\"time_t\"]=pd.to_datetime(df_t['date']+\" \"+df_t['time']) #Lo guardamos en una nueva columna\n",
    "print(df_t)\n",
    "print(df_t[\"time_t\"].dt.year)\n",
    "print(df_t[\"time_t\"].dt.strftime(\"%Y/%m/%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2014-01-01 00:30:00', '2014-01-01 01:00:00',\n",
      "               '2014-01-01 01:30:00', '2014-01-01 02:00:00',\n",
      "               '2014-01-01 02:30:00', '2014-01-01 03:00:00',\n",
      "               '2014-01-01 03:30:00', '2014-01-01 04:00:00',\n",
      "               '2014-01-01 04:30:00', '2014-01-01 05:00:00',\n",
      "               ...\n",
      "               '2018-02-08 18:30:00', '2018-02-08 19:00:00',\n",
      "               '2018-02-08 19:30:00', '2018-02-08 20:00:00',\n",
      "               '2018-02-08 20:30:00', '2018-02-08 21:00:00',\n",
      "               '2018-02-08 21:30:00', '2018-02-08 22:00:00',\n",
      "               '2018-02-08 22:30:00', '2018-02-08 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='time_t', length=68992, freq=None)\n",
      "Index([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       ...\n",
      "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
      "      dtype='int32', name='time_t', length=68992)\n"
     ]
    }
   ],
   "source": [
    "#Fijamos un nuevo índice\n",
    "df_t=df_t.set_index(\"time_t\")\n",
    "print(df_t.index)\n",
    "print(df_t.index.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           date      time      DOY       Ta        Pa  \\\n",
      "2014-01-01 00:30:00  2014-01-01  00:30:00   1.0208  285.499  100523.0   \n",
      "2014-01-01 01:00:00  2014-01-01  01:00:00   1.0416  285.169  100531.0   \n",
      "2014-01-01 01:30:00  2014-01-01  01:30:00   1.0624  285.089  100526.0   \n",
      "2014-01-01 02:00:00  2014-01-01  02:00:00   1.0833  285.388  100514.0   \n",
      "2014-01-01 02:30:00  2014-01-01  02:30:00   1.1041  285.454  100498.0   \n",
      "...                         ...       ...      ...      ...       ...   \n",
      "2018-02-08 21:00:00  2018-02-08  21:00:00  39.8748  284.809  100917.0   \n",
      "2018-02-08 21:30:00  2018-02-08  21:30:00  39.8956  284.447  100944.0   \n",
      "2018-02-08 22:00:00  2018-02-08  22:00:00  39.9165  284.535  100961.0   \n",
      "2018-02-08 22:30:00  2018-02-08  22:30:00  39.9373  283.947  100990.0   \n",
      "2018-02-08 23:00:00  2018-02-08  23:00:00  39.9581  284.156  100990.0   \n",
      "\n",
      "                          RH       Td       Tc        Rn     LWin  ...  \\\n",
      "2014-01-01 00:30:00  87.5984      NaN  285.499       NaN      NaN  ...   \n",
      "2014-01-01 01:00:00  88.4022      NaN  285.169       NaN      NaN  ...   \n",
      "2014-01-01 01:30:00  89.6953      NaN  285.089       NaN      NaN  ...   \n",
      "2014-01-01 02:00:00  87.9180      NaN  285.388       NaN      NaN  ...   \n",
      "2014-01-01 02:30:00  84.4577      NaN  285.454       NaN      NaN  ...   \n",
      "...                      ...      ...      ...       ...      ...  ...   \n",
      "2018-02-08 21:00:00  87.2794  8.53473  284.809 -111.9970  622.180  ...   \n",
      "2018-02-08 21:30:00  81.5375  6.87156  284.447  -63.4305  669.949  ...   \n",
      "2018-02-08 22:00:00  77.7024  6.43326  284.535  -70.1655  664.107  ...   \n",
      "2018-02-08 22:30:00  81.4990  6.62946  283.947  -95.6326  635.117  ...   \n",
      "2018-02-08 23:00:00  78.2415  5.94753  284.156  -83.2179  647.099  ...   \n",
      "\n",
      "                     Ts_2_1_1  Ts_3_1_1  SWC_1_1_1  SWC_2_1_1  SWC_3_1_1  \\\n",
      "2014-01-01 00:30:00   286.550   285.912   0.580774   0.677433   0.264485   \n",
      "2014-01-01 01:00:00   286.498   285.869   0.581969   0.677369   0.264282   \n",
      "2014-01-01 01:30:00   286.431   285.818   0.583308   0.677512   0.264079   \n",
      "2014-01-01 02:00:00   286.368   285.768   0.584545   0.677424   0.263918   \n",
      "2014-01-01 02:30:00   286.329   285.730   0.585552   0.677087   0.264359   \n",
      "...                       ...       ...        ...        ...        ...   \n",
      "2018-02-08 21:00:00   287.524   287.100   0.269830   0.324491   0.168710   \n",
      "2018-02-08 21:30:00   287.505   287.074   0.270332   0.324650   0.169308   \n",
      "2018-02-08 22:00:00   287.483   287.047   0.270886   0.324739   0.169821   \n",
      "2018-02-08 22:30:00   287.444   286.994   0.271494   0.324923   0.170493   \n",
      "2018-02-08 23:00:00   287.406   286.938   0.272248   0.325303   0.170982   \n",
      "\n",
      "                     SHF_1_1_1  SHF_2_1_1  SHF_3_1_1         LE         H  \n",
      "2014-01-01 00:30:00   1.899400   0.491621   0.750120   0.987573   2.10820  \n",
      "2014-01-01 01:00:00   1.439690   0.225682   0.559402   0.167466  -4.62751  \n",
      "2014-01-01 01:30:00   0.982225  -0.032565   0.359773  -0.209549 -25.06920  \n",
      "2014-01-01 02:00:00   0.527264  -0.292637   0.154871   1.012810 -19.36180  \n",
      "2014-01-01 02:30:00   0.088923  -0.545190  -0.036778  -1.875870  -2.52581  \n",
      "...                        ...        ...        ...        ...       ...  \n",
      "2018-02-08 21:00:00   1.388390   0.480249  -0.708542   0.028853 -10.19220  \n",
      "2018-02-08 21:30:00   1.220350   0.355083  -1.070870  10.821500 -11.88980  \n",
      "2018-02-08 22:00:00   1.017980   0.206502  -1.642580  28.889900 -46.52960  \n",
      "2018-02-08 22:30:00   0.785127   0.043090  -1.978500   1.498780 -16.58690  \n",
      "2018-02-08 23:00:00   0.531903  -0.125031  -2.315050  14.333400 -22.25020  \n",
      "\n",
      "[71998 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#Ahora cubrimos todo el espacio\n",
    "ti=df_t.index.min()\n",
    "tf=df_t.index.max()\n",
    "time_total=pd.date_range(start=ti,end=tf,freq=\"30min\")\n",
    "df_t=df_t.reindex(time_total)\n",
    "print(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links de interés\n",
    "- Datasets https://www.kaggle.com/datasets\n",
    "- Documentación de Pandas https://pandas.pydata.org/docs/index.html \n",
    "- Cookbook de pandas https://pandas.pydata.org/docs/user_guide/cookbook.html\n",
    "- Estructura y un par de cosas sobre data engineering https://apmonitor.com/pds/index.php/Main/DataPreparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
