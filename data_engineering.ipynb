{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas por agregar\n",
    "- visualización\n",
    "- filtrado\n",
    "- incluir resumen de formas de indexado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links de interés\n",
    "- Datasets https://www.kaggle.com/datasets\n",
    "- Documentación de Pandas https://pandas.pydata.org/docs/index.html \n",
    "- Cookbook de pandas https://pandas.pydata.org/docs/user_guide/cookbook.html\n",
    "- Estructura y un par de cosas sobre data engineering https://apmonitor.com/pds/index.php/Main/DataPreparation\n",
    "- Indexing and selecting data, pandas: https://pandas.pydata.org/docs/user_guide/indexing.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import importantes y cargo pickles de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "kagglehub.dataset_download(\"isathyam31/adult-income-prediction-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo pickles\n",
    "with open(\"df.pkl\",\"rb\") as file:\n",
    "    df=pickle.load(file)\n",
    "    \n",
    "with open(\"df_t.pkl\",\"rb\") as file:\n",
    "    df_t=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recolectar data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función más usada, lejos es `read_csv` de pandas, donde basta que demos el path del archivo y su nombre, y se leerá si no hay mayor problema. Por default, la primera fila se transforma en las columnas del dataframe, que podemos ver usando `dataframe.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/capitanespiral/Documents/GitHub/data_science\" #Aquí introducir tu path\n",
    "filename=\"data.csv\"\n",
    "\n",
    "df=pd.read_csv(f\"{path}/{filename}\")\n",
    "#Display entrega mucho mejor resultado que print para los dataframes!\n",
    "display(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Opciones más usadas de `read_csv`:\n",
    "- **sep o delimiter** &rarr; El separador de la data, usualmente se encuentra solo pero a veces es mejor darlo explícitamente. (en el caso que se confunda el identificador automático)\n",
    "- **header** &rarr; Número de fila que se toma como nombre de columnas y desde el cual comienza la data, por default, cero (inicio del .csv).\n",
    "- **skiprows** &rarr; Filas a saltar desde el inicio del archivo (indexeando desde cero, se puede entregar lista o tupla)\n",
    "- **skipfooter** &rarr; Filas a saltar desde el final del archivo.\n",
    "- **usecols** &rarr; Subset de columnas a usar (secuencia de números o nombres explícitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la primera fila está mala, cambiamos el header\n",
    "df1=pd.read_csv(\"data_bad_first_row.csv\") #Salió pésimo\n",
    "df2=pd.read_csv(\"data_bad_first_row.csv\",header=1) #Mucho mejor\n",
    "\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la segunda está mala\n",
    "df3=pd.read_csv(\"data_bad_second_row.csv\") #Primer dato pésimo\n",
    "df4=pd.read_csv(\"data_bad_second_row.csv\",skiprows=[1],header=0) #Nos saltamos la segunda fila y conservamos el header\n",
    "\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionemos ciertas columnas no más\n",
    "df5=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[0,3]) #Puede ser con números, aquí la primera y la cuarta\n",
    "df6=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=range(4)) #Puede ser con iteradores, acá me entrega de la primera A la cuarta\n",
    "df7=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[\"age\",\"education\",\"workclass\"]) #Puede ser con los nombres explícitos\n",
    "\n",
    "display(df5)\n",
    "display(df6)\n",
    "display(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df3,df4,df5,df6,df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de series de tiempo, hay que saber trabajar con `Timestamps`, `Datetime`, `Timedelta`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones generales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pd.to_datetime()** &rarr; Transforma lo que le entregues en un \"Datetime\", funciona aceptando varios formatos y si le entregas secuencias.\n",
    "- **pd.date_range()** &rarr; Para crear puntos en el tiempo equiespaceados, con un \"start\" un \"end\", posibilidad de \"periods\" o \"freq\"\n",
    "    - **freq** más comunes:\"y\" (años),\"m\" (meses),\"W\" (semana), \"B\" (business day), \"d\" (días), \"h\" (horas), \"min\" (minutos), \"s\" (segundos) Ojo que hay *infinitas* opciones! revisar en https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "- **df.resample().func()** &rarr; Entregando como variable una frecuencia, podemos \"resamplear\" según la función \"func\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datetime con varios formatos\n",
    "dt1=pd.to_datetime([\"13/1/2018\", np.datetime64(\"2018-01-13\"), datetime.datetime(2018, 1, 13)],dayfirst=True)\n",
    "print(\"dt1:\",dt1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##date_range\n",
    "#Creando una lista de tiempo cada tres horas\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt2=pd.date_range(start=t1,end=t2,freq=\"3h\")\n",
    "print(\"dt2:\",dt2,\"\\n\")\n",
    "\n",
    "#Lo mismo pero con 15 minutos\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt3=pd.date_range(start=t1,end=t2,freq=\"15min\")\n",
    "print(\"dt3:\",dt3,\"\\n\")\n",
    "\n",
    "#Si tengo periodos y frecuencia\n",
    "dt4=pd.date_range(start=\"2018-8-1\", periods=5, freq=\"2d\")\n",
    "print(\"dt4:\",dt4,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como usar el resampleo\n",
    "idx = pd.date_range(\"2018-01-01\", periods=10, freq=\"h\") #ojo que 1h = h\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(\"ts\",ts,\"\\n\",sep=\"\\n\")\n",
    "#Downsample (también muy usado el sum)\n",
    "ts_downsampled=ts.resample(\"2h\").mean() #LEJOS el más útil\n",
    "print(\"ts_downsampled\",ts_downsampled,\"\\n\",sep=\"\\n\")\n",
    "#upsample (también muy usado bfill)\n",
    "ts_upsampled=ts.resample(\"30min\").ffill() #Sería interesante, acá interpolar\n",
    "print(\"ts_upsampled\",ts_upsampled,\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt1,dt2,dt3,dt4,idx,ts,ts_upsampled,ts_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajemos con data de verdad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=pd.read_csv(\"biomet1.csv\",skiprows=[1],header=0) #Tenemos caso de segunda linea sin sentido\n",
    "df_t[\"time_t\"]=pd.to_datetime(df_t['date']+\" \"+df_t['time']) #Lo guardamos en una nueva columna\n",
    "display(df_t)\n",
    "print(\"\\nLa columna nueva:\",df_t[\"time_t\"],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos servirá ahora\n",
    "- **datetime.min() y .max()** &rarr; Evidente\n",
    "- **datetimeindex.atributos** &rarr; nos permite acceder a muchas funciones de tiempo como \"hour\",\"day\",\"minute\",\"second\",\"dayofyear\", \"strftime\", entre otras (si es una serie, no un índice, agregar dt). La totalidad de atributos y métodos en https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html. La totalidad de formatos para \"strftime\" en https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos acceder a propiedades o métodos específicos de un objeto tipo \"datetime\" usando el \"dt\"\n",
    "print(\"Solo el año:\",df_t[\"time_t\"].dt.year,\"\\n\",sep=\"\\n\")\n",
    "print(\"Cambio el formato:\",df_t[\"time_t\"].dt.strftime(\"%Y  /   %m   /  %d\"),\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijamos un nuevo índice\n",
    "df_t=df_t.set_index(\"time_t\") #Esto \"traslada\" la columna \"time_t\" (ya no existe como columna) - Y pasa a ser datetimeindex\n",
    "df_t=df_t.drop(columns = [\"date\",\"time\"]) #Boto las columnas que ya no necesito\n",
    "display(df_t)\n",
    "print(\"Y el nuevo índice:\")\n",
    "print(df_t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al fijarlo como índice, ahora podemos accesar simplemente con \".atributo\"\n",
    "display(df_t)\n",
    "print(\"Solo el día:\",df_t.index.day,\"\\n\",sep=\"\\n\")\n",
    "print(\"Solo el día juliano:\",df_t.index.dayofyear,\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos notar que hay vaciós en la data, en específico 3!\n",
    "fig,ax=plt.subplots(figsize=(16,10))\n",
    "ax.scatter(df_t.index,df_t.index,s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora cubrimos todo el espacio\n",
    "ti=df_t.index.min()\n",
    "tf=df_t.index.max()\n",
    "time_total=pd.date_range(start=ti,end=tf,freq=\"30min\")\n",
    "df_t=df_t.reindex(time_total) #Esta función redefine el índice, conservando datos y agregando nans si el nuevo índice coincide con el anterior o si no existe (para cada fila!)\n",
    "display(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se rellenó\n",
    "fig,ax=plt.subplots(figsize=(16,10))\n",
    "ax.scatter(df_t.index,df_t.index,s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamos como pickle los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El primer dataframe\n",
    "with open('df.pkl',\"wb\") as file:\n",
    "    pickle.dump(df,file)\n",
    "\n",
    "#El dataframe de serie de tiempo\n",
    "with open('df_t.pkl',\"wb\") as file:\n",
    "    pickle.dump(df_t,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver data y estadística básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entender que *pandas* tiene dos grandes tipos de objetos: `Series` y `DataFrame`. El primero es como un \"vector\" (unidimensional) y el segundo está compuesto por varias `Series`, siendo como una \"matriz\". Y cada uno siempre tiene asociado su `Index`, que puede ser numérico o de cualquier naturaleza (uno común, temporal).\n",
    "\n",
    "La forma básica de indexar cada tipo tiene distintos resultados:\n",
    "- **Series[label]** &rarr; Dará un valor escalar en tal posición acorde al `Index`.\n",
    "- **DataFrame[colname]** &rarr; Dará una *Serie* correspondiente a tal nombre de columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accedo a una columna, me entrega a una serie, y despues a un elemento en específico\n",
    "print(\"**Dataframe**\")\n",
    "print(\"Edad\",df[\"age\"],\"\\n\",sep=\"\\n\")\n",
    "print(\"Tercer valor:\",df[\"age\"][2],\"\\n\") #df[\"age\"] es una serie, entonces df[\"age\"][2] es el valor asociado al indice 2 de la serie\n",
    "\n",
    "#Si el índice no es numérico, esto igual se puede hacer, pero se recomienda indexar acorde al índice\n",
    "print(\"**Dataframe temporal**\")\n",
    "print(\"Calor sensible\",df_t[\"H\"],\"\\n\",sep=\"\\n\") #Notar que el índice es temporal\n",
    "print(\"Tercer valor indexando con 'int':\",df_t[\"H\"][2]) #Obtengo el tercer valor -> Notar advertencia de pandas!\n",
    "print(\"Tercer valor indexando con un 'label' del 'index':\",df_t[\"H\"][\"2014-01-01 01:30:00\"]) #Lo mismo pero con el tiempo, engorroso pero preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre podemos acceder a **varios valores** de una *serie* (con indexación típica de python) o **varias columnas** en un *dataframe* (agregando un nuevo []:). Notar que esto último entrega un nuevo `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[[\"age\",\"education\"]])\n",
    "display(df[[\"age\",\"education\"]][1:5]) \n",
    "print(\"Del segundo al quinto valor de una columna:\",df[\"age\"][1:5],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También usando slices de enteros en una *serie* o *dataframe* (en este caso se accesarán filas, no columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexado clásico de python sobre una serie\n",
    "print(\"Del primer al quinto dato:\",df[\"age\"][:5],\"\\n\",sep=\"\\n\") \n",
    "print(\"Los datos pares:\",df[\"age\"][::2],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "#Indexado clásico de python sobre un dataframe\n",
    "print(\"\\nDel primer al quinto dato:\")\n",
    "display(df_t[:5]) \n",
    "print(\"\\nLos datos dados vuelta:\")\n",
    "display(df_t[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar algunas posiciones basta con entregar una lista, pero solo funciona con series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Segundo, tercer y sexto dato de 'age':\")\n",
    "print(df[\"age\"][[1,2,5]])\n",
    "\n",
    "print(\"\\nSegundo, tercer y sexto dato de 'H':\")\n",
    "df_t[\"H\"][[1,2,5]] #Notar el warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar con .loc e .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para indexar también se tienen los métodos `.loc` y `.iloc`(para *series* y *dataframes*)\n",
    "1. `.loc` &rarr; trabaja con labels o con arreglos booleanos.\n",
    "2. `.iloc` &rarr; trabaja con posisiones con enteros (desde 0 a -1) o con arreglos booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df.drop([1]) #Boto la segunda fila\n",
    "display(df_temp)\n",
    "\n",
    "print(\"Con loc\",df_temp.loc[2],\"\\n\",sep=\"\\n\") #Aquí 2 es interpretado como \"label\", será la nueva segunda fila\n",
    "\n",
    "print(\"Con iloc\",df_temp.iloc[2],\"\\n\",sep=\"\\n\") #Aquí como entero, será la tercera fila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para llamar a varios elementos no secuenciales, usamos también listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando listas de elementos\n",
    "print(\"Usando listas:\")\n",
    "\n",
    "display(df_temp.loc[[0,3,5]]) #El label 0, 3, 5\n",
    "\n",
    "display(df_temp.iloc[[0,3,5]]) #Las posiciones asociados (otro label)\n",
    "\n",
    "#También usando \"slices\"\n",
    "print(\"\\nUsando slices ahora:\")\n",
    "print(\"El dataframe con una fila menos:\")\n",
    "display(df_temp.loc[0:5])\n",
    "display(df_temp.iloc[0:5])\n",
    "\n",
    "print(\"\\nEl dataframe original\")\n",
    "display(df.loc[0:5])\n",
    "display(df.iloc[0:5])\n",
    "print(\"En este caso funcionan igual por la naturaleza de este índice. NOTAR se incluye el PRINCIPIO Y EL FINAL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamando distintas filas y columnas usando `.loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas loc\n",
    "print(\"Slice y columna - loc\",df_temp.loc[2:9,\"age\"],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - loc\")\n",
    "display(df_temp.loc[2:9,\"age\":\"sex\"])\n",
    "\n",
    "print(\"\\nFilas y columnas - loc\")\n",
    "display(df_temp.loc[[5,3,7],[\"education\",\"age\",\"country\",\"race\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamando distintas filas y columnas usando `.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas iloc (aquí las columnas se preguntan también posicionalmente)\n",
    "\n",
    "print(\"Slice y columna - iloc\",df_temp.iloc[2:9,0],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - iloc\")\n",
    "display(df_temp.iloc[2:9,0:7])\n",
    "\n",
    "print(\"\\nFilas y columnas - iloc\")\n",
    "display(df_temp.iloc[[5,3,7],[1,0,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando slices en `.loc` siempre tiene que ser algo compatible con el índice del df (o al menos *transformable* en este!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con loc podemos usar slices compatibles con el tipo de índice\n",
    "display(df_t.loc[\"20150112\":\"20160101\"])\n",
    "display(df_t.loc[\"2015\":\"2017\"])\n",
    "display(df_t.loc[\"2015\"]) #Todo lo que tenga 2015!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclando posición y label indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con loc, en el índice de las filas podemos indexar posicionalmente el índice:\n",
    "display(df.loc[df.index[[0,2,5]],[\"age\",\"education\"]])\n",
    "display(df_t.loc[df_t.index[[0,2,5]],[\"H\",\"LE\"]])\n",
    "print(\"\\nNotar que df_t.index me entrega los labels que busco en tales posiciones:\")\n",
    "print(df_t.index[[0,2,5]])\n",
    "\n",
    "#Con iloc, es un poco más enredado, pero podemos llamar el label de la columna:\n",
    "display(df.iloc[[0,2,5],df.columns.get_indexer([\"sex\"])])\n",
    "display(df_t.iloc[[0,2,5],df_t.columns.get_indexer([\"H\",\"LE\"])])\n",
    "\n",
    "print(\"\\nNotar que df_t.columns.get_indexer me entrega las posiciones que busco en tales labels:\")\n",
    "print(df_t.columns.get_indexer([\"H\",\"LE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, indexado básico y `.loc` e `.iloc` gestionan *múltiples casos* de indexado. Si queremos solo conseguir *un* valor, se recomienda usar `.at` y `.iat` (mucho más veloces para esto). Uno ve labels y el otro posiciones respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.at[2,\"age\"])\n",
    "print(df.iat[2,0])\n",
    "\n",
    "print(df_t.at[df_t.index[0],\"H\"])\n",
    "print(df_t.iat[0,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar con booleanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de las cosas más poderosas y usadas en *Pandas*. Los operadores entre comparaciones son `|` (or), `&` (and), `~` (not) y se deben agrupar con parentesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estamos trabajando con `series` se trabaja igual que un arreglo numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con series\n",
    "s=df[\"age\"]\n",
    "print(\"Serie original:\")\n",
    "print(s)\n",
    "print(\"\\nSerie siendo comparada:\")\n",
    "print(s<30)\n",
    "\n",
    "print(\"\\nEdades menores a 30:\")\n",
    "print(s[s<30]) #Claro ques era lo mismo usar df[\"age\"][df[\"age\"]<30]\n",
    "\n",
    "print(\"\\nEdades menores a 30 o mayor/igual a 40:\")\n",
    "print(s[(s<30) | (s>= 40)])\n",
    "\n",
    "print(\"\\nEdades entre 30 y 35:\")\n",
    "print(s[(s>=30) & (s<=35)])\n",
    "\n",
    "print(\"\\nEdades distintas de 30:\")\n",
    "print(s[s!=30])\n",
    "print(s[~(s==30)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos trabajar con `Dataframes`, basta con entregar un vector booleano del mismo largo que el `index`, por ejemplo, una columna del mismo `Dataframe`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La columna de edad:\",df[\"age\"],sep=\"\\n\")\n",
    "print(\"\\nSi usamos alguna comparación se transforma en 'booleana':\",df[\"age\"]>30,sep=\"\\n\")\n",
    "print(\"\\nY con esto podemos FILTRAR el dataframe original:\")\n",
    "display(df[df[\"age\"]>30])\n",
    "\n",
    "print(\"Por supuesto que esto puede ser TAN complejo como uno quiera!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos resetear el índice basta con usar `.reset_index()`, que almacenará el índice antigüo como una columna, si no queremos que lo guarde, basta con usar *drop=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtrado:\")\n",
    "display(df[df[\"age\"]>30])\n",
    "\n",
    "print(\"Filtrado con nuevo índice y viejo índice como columna:\")\n",
    "display(df[df[\"age\"]>30].reset_index())\n",
    "\n",
    "print(\"Filtrado con nuevo índice nada más:\")\n",
    "display(df[df[\"age\"]>30].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el metodo `.map()` o comprensión de listas podemos realizar criterios más complejos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método más rápido (busco gente casada)\n",
    "criterio=df[\"marital-status\"].map(lambda x: x.startswith(\" M\")) #Ojo que datos parten con un espacio aparentemente\n",
    "print(criterio)\n",
    "display(df[criterio])\n",
    "\n",
    "#Más lento pero idéntico\n",
    "display(df[[x.startswith(\" M\") for x in df[\"marital-status\"]]])\n",
    "\n",
    "#Mezclando esto y otras condiciones\n",
    "display(df[criterio & (df[\"education-num\"]>=13)]) #Buscando gente casada con algún grado universitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muy util para seleccionar categorias específicas\n",
    "criterio=df[\"relationship\"].map(lambda x: x in (\" Husband\",\" Wife\",\" Own-child\"))\n",
    "df[criterio]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `.loc` e `.iloc` podemos filtrar más aun. Eso si, para `.iloc` se vuelve necesario usar el atributo `.values`, que nos entrega el arreglo numpy con la data almacenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio=df[\"marital-status\"].map(lambda x: x.startswith(\" M\"))\n",
    "#Con loc es muy directo\n",
    "display(df.loc[criterio & (df[\"education-num\"]>=13),\"age\":\"education\"])\n",
    "\n",
    "#iloc tira error de la misma manera, tenemos que usar \"values\"\n",
    "#display(df.iloc[criterio & (df[\"education-num\"]>=13),[5,3]]) esto tira error!\n",
    "aux_crit=criterio & (df[\"education-num\"]>=13)\n",
    "display(df.iloc[aux_crit.values,[5,3]]) #Aquí ningun problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notar que:\")\n",
    "print(type(df.values))\n",
    "print()\n",
    "display(df.values)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método where() y masking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para `Series`, usar un arreglo booleano usualmente entrega un subset, si queremos que conserve la forma de la data original podemos usar `where`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La serie original:\")\n",
    "print(df_t[\"H\"])\n",
    "print()\n",
    "print(\"La serie filtrada para valores positivos:\")\n",
    "print(df_t[\"H\"][df_t[\"H\"]>0])\n",
    "\n",
    "#Ahora usando where\n",
    "print(\"\\nCon where resulta:\")\n",
    "print(df_t[\"H\"].where(df_t[\"H\"]>0)) #Se reemplazan los valores que no cumplen la condición con NaN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacer este tipo de evaluaciones para un `DataFrame`, conserva el tamaño (está aplicando `where` bajo la mesa). Pero si usamos where, tenemos la posibilidad de escoger otro argumento que reemplazará los valores donde la condición sea falsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El dataframe original:\")\n",
    "display(df_t)\n",
    "print(\"Solo valores positivos, negativos reemplazados con NaN:\")\n",
    "display(df_t[df_t>0]) #Se transforman en NaN\n",
    "print(\"Reemplazados con cero:\")\n",
    "display(df_t.where(df_t>0,0))\n",
    "print(\"Reemplazados con su valor positivo:\")\n",
    "display(df_t.where(df_t>0,-df_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede recibir una función en ambos argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.where(lambda x:x>0,lambda x:x+100) #Lo primero es lo que busco, lo segundo con que lo reemplazo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el método `.mask()` hace lo contrario que `.where()`. O sea reemplaza cuando algo es verdadero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.mask(df_t>0) #Basicamente todo al revés!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más opciones de seleccionar/indexar data en https://pandas.pydata.org/docs/user_guide/indexing.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras funciones para ver la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una serie de funciones que nos permiten visualizar la data. Dentro de las más básicas:\n",
    "- **df.head(n)** &rarr; nos permite ver las primeras \"n\" filas (sin n, por default 5), funciona para `Series` y `DataFrame`.\n",
    "- **df.tail(n)** &rarr; nos permite ver las últimas \"n\" filas (lo mismo), funciona para `Series` y `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para dataframes\n",
    "display(df.head())\n",
    "display(df.head(10))\n",
    "\n",
    "#Para una serie\n",
    "print(df[\"age\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail())\n",
    "\n",
    "display(df[\"workclass\"].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener una descripción estadística básica de nuestra data podemos usar `df.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe())\n",
    "df_t.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
