{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas por agregar\n",
    "- Sección de series de tiempo (datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitanespiral/Documents/GitHub/data_science/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/capitanespiral/.cache/kagglehub/datasets/isathyam31/adult-income-prediction-classification/versions/1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "kagglehub.dataset_download(\"isathyam31/adult-income-prediction-classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función más usada, lejos es `read_csv` de pandas, donde basta que demos el path del archivo y su nombre, y se leerá si no hay mayor problema. Por default, la primera fila se transforma en las columnas del dataframe, que podemos ver usando `dataframe.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt    education  education-num  \\\n",
      "0       39          State-gov   77516    Bachelors             13   \n",
      "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
      "2       38            Private  215646      HS-grad              9   \n",
      "3       53            Private  234721         11th              7   \n",
      "4       28            Private  338409    Bachelors             13   \n",
      "...    ...                ...     ...          ...            ...   \n",
      "32556   27            Private  257302   Assoc-acdm             12   \n",
      "32557   40            Private  154374      HS-grad              9   \n",
      "32558   58            Private  151910      HS-grad              9   \n",
      "32559   22            Private  201490      HS-grad              9   \n",
      "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   White   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
      "...                    ...                 ...             ...     ...   \n",
      "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
      "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
      "32558              Widowed        Adm-clerical       Unmarried   White   \n",
      "32559        Never-married        Adm-clerical       Own-child   White   \n",
      "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week         country  \\\n",
      "0         Male          2174             0              40   United-States   \n",
      "1         Male             0             0              13   United-States   \n",
      "2         Male             0             0              40   United-States   \n",
      "3         Male             0             0              40   United-States   \n",
      "4       Female             0             0              40            Cuba   \n",
      "...        ...           ...           ...             ...             ...   \n",
      "32556   Female             0             0              38   United-States   \n",
      "32557     Male             0             0              40   United-States   \n",
      "32558   Female             0             0              40   United-States   \n",
      "32559     Male             0             0              20   United-States   \n",
      "32560   Female         15024             0              40   United-States   \n",
      "\n",
      "       salary  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "32556       0  \n",
      "32557       1  \n",
      "32558       0  \n",
      "32559       0  \n",
      "32560       1  \n",
      "\n",
      "[32561 rows x 15 columns]\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'country', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/capitanespiral/Documents/GitHub/data_science\"\n",
    "filename=\"data.csv\"\n",
    "\n",
    "df=pd.read_csv(f\"{path}/{filename}\")\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Opciones más usadas de `read_csv`:\n",
    "- **sep o delimiter** &rarr; El separador de la data, usualmente se encuentra solo pero a veces es mejor darlo explícitamente. (en el caso que se confunda el identificador automático)\n",
    "- **header** &rarr; Número de fila que se toma como nombre de columnas y desde el cual comienza la data, por default, cero (inicio del .csv).\n",
    "- **skiprows** &rarr; Filas a saltar desde el inicio del archivo (indexeando desde cero, se puede entregar lista o tupla)\n",
    "- **skipfooter** &rarr; Filas a saltar desde el final del archivo.\n",
    "- **usecols** &rarr; Subset de columnas a usar (secuencia de números o nombres explícitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la primera fila está mala, cambiamos el header\n",
    "df1=pd.read_csv(f\"{path}/data_bad_first_row.csv\") #Salió pésimo\n",
    "df2=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1) #Mucho mejor\n",
    "\n",
    "#Si la segunda está mala\n",
    "df3=pd.read_csv(f\"{path}/data_bad_second_row.csv\") #Primer dato pésimo\n",
    "df4=pd.read_csv(f\"{path}/data_bad_second_row.csv\",skiprows=[1],header=0) #Nos saltamos la segunda fila y conservamos el header\n",
    "\n",
    "#Seleccionemos ciertas columnas no más\n",
    "df5=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1,usecols=[0,3]) #Puede ser con números, aquí la primera y la cuarta\n",
    "df6=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1,usecols=range(4)) #Puede ser con iteradores, acá me entrega de la primera A la cuarta\n",
    "df7=pd.read_csv(f\"{path}/data_bad_first_row.csv\",header=1,usecols=[\"age\",\"education\",\"workclass\"]) #Puede ser con los nombres explícitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df3,df4,df5,df6,df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de series de tiempo, hay que saber trabajar con `Timestamps`, `Datetime`, `Timedelta`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones generales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pd.to_datetime()** &rarr; Transforma lo que le entregues en un \"Datetime\", funciona aceptando varios formatos y si le entregas secuencias.\n",
    "- **pd.date_range()** &rarr; Para crear puntos en el tiempo equiespaceados, con un \"start\" un \"end\", posibilidad de \"periods\" o \"freq\"\n",
    "    - **freq** más comunes:\"y\" (años),\"m\" (meses),\"W\" (semana), \"B\" (business day), \"d\" (días), \"h\" (horas), \"min\" (minutos), \"s\" (segundos) Ojo que hay *infinitas* opciones! revisar en https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "- **df.resample().func()** &rarr; Entregando como variable una frecuencia, podemos \"resamplear\" según la función \"func\"\n",
    "- **datetime.min() y .max()** &rarr; Evidente\n",
    "- **datetimeindex.atributos** &rarr; nos permite acceder a muchas funciones de tiempo como \"hour\",\"day\",\"minute\",\"second\",\"dayofyear\", \"strftime\", entre otras (si es una serie, no un índice, agregar dt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt1: DatetimeIndex(['2018-01-13', '2018-01-13', '2018-01-13'], dtype='datetime64[ns]', freq=None)\n",
      "dt2: DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 03:00:00',\n",
      "               '2000-01-01 06:00:00', '2000-01-01 09:00:00',\n",
      "               '2000-01-01 12:00:00', '2000-01-01 15:00:00',\n",
      "               '2000-01-01 18:00:00', '2000-01-01 21:00:00',\n",
      "               '2000-01-02 00:00:00', '2000-01-02 03:00:00',\n",
      "               ...\n",
      "               '2000-03-08 21:00:00', '2000-03-09 00:00:00',\n",
      "               '2000-03-09 03:00:00', '2000-03-09 06:00:00',\n",
      "               '2000-03-09 09:00:00', '2000-03-09 12:00:00',\n",
      "               '2000-03-09 15:00:00', '2000-03-09 18:00:00',\n",
      "               '2000-03-09 21:00:00', '2000-03-10 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=553, freq='3h')\n",
      "dt3: DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 00:15:00',\n",
      "               '2000-01-01 00:30:00', '2000-01-01 00:45:00',\n",
      "               '2000-01-01 01:00:00', '2000-01-01 01:15:00',\n",
      "               '2000-01-01 01:30:00', '2000-01-01 01:45:00',\n",
      "               '2000-01-01 02:00:00', '2000-01-01 02:15:00',\n",
      "               ...\n",
      "               '2000-10-02 21:45:00', '2000-10-02 22:00:00',\n",
      "               '2000-10-02 22:15:00', '2000-10-02 22:30:00',\n",
      "               '2000-10-02 22:45:00', '2000-10-02 23:00:00',\n",
      "               '2000-10-02 23:15:00', '2000-10-02 23:30:00',\n",
      "               '2000-10-02 23:45:00', '2000-10-03 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=26497, freq='15min')\n",
      "dt4: DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "               '2018-01-05'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "ts 2018-01-01 00:00:00    0\n",
      "2018-01-01 01:00:00    1\n",
      "2018-01-01 02:00:00    2\n",
      "2018-01-01 03:00:00    3\n",
      "2018-01-01 04:00:00    4\n",
      "2018-01-01 05:00:00    5\n",
      "2018-01-01 06:00:00    6\n",
      "2018-01-01 07:00:00    7\n",
      "2018-01-01 08:00:00    8\n",
      "2018-01-01 09:00:00    9\n",
      "Freq: h, dtype: int64\n",
      "ts_resampled 2018-01-01 00:00:00    0.5\n",
      "2018-01-01 02:00:00    2.5\n",
      "2018-01-01 04:00:00    4.5\n",
      "2018-01-01 06:00:00    6.5\n",
      "2018-01-01 08:00:00    8.5\n",
      "Freq: 2h, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##datetime con varios formatos\n",
    "dt1=pd.to_datetime([\"13/1/2018\", np.datetime64(\"2018-01-13\"), datetime.datetime(2018, 1, 13)],dayfirst=True)\n",
    "print(\"dt1:\",dt1)\n",
    "\n",
    "##date_range\n",
    "#Creando una lista de tiempo cada tres horas\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt2=pd.date_range(start=t1,end=t2,freq=\"3h\")\n",
    "print(\"dt2:\",dt2)\n",
    "\n",
    "#Lo mismo pero con 15 minutos\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-10-3\"\n",
    "dt3=pd.date_range(start=t1,end=t2,freq=\"15min\")\n",
    "print(\"dt3:\",dt3)\n",
    "\n",
    "#Si tengo periodos y frecuencia\n",
    "dt4=pd.date_range(\"2018-01-01\", periods=5, freq=\"d\")\n",
    "print(\"dt4:\",dt4)\n",
    "\n",
    "#Como usar el resampleo\n",
    "idx = pd.date_range(\"2018-01-01\", periods=10, freq=\"h\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(\"ts\",ts)\n",
    "ts_resampled=ts.resample(\"2h\").mean()\n",
    "print(\"ts_resampled\",ts_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=pd.read_csv(\"biomet1.csv\",skiprows=[1],header=0) #Tenemos caso de segunda linea sin sentido\n",
    "df_t[\"time_t\"]=pd.to_datetime(df_t['date']+\" \"+df_t['time']) #Lo guardamos en una nueva columna\n",
    "print(df_t)\n",
    "print(df_t[\"time_t\"].dt.year)\n",
    "print(df_t[\"time_t\"].dt.strftime(\"%Y/%m/%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijamos un nuevo índice\n",
    "df_t=df_t.set_index(\"time_t\")\n",
    "print(df_t.index)\n",
    "print(df_t.index.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora cubrimos todo el espacio\n",
    "ti=df_t.index.min()\n",
    "tf=df_t.index.max()\n",
    "time_total=pd.date_range(start=ti,end=tf,freq=\"30min\")\n",
    "df_t=df_t.reindex(time_total)\n",
    "print(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links de interés\n",
    "- Datasets https://www.kaggle.com/datasets\n",
    "- Documentación de Pandas https://pandas.pydata.org/docs/index.html \n",
    "- Cookbook de pandas https://pandas.pydata.org/docs/user_guide/cookbook.html\n",
    "- Estructura y un par de cosas sobre data engineering https://apmonitor.com/pds/index.php/Main/DataPreparation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
