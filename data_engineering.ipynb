{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosas por agregar\n",
    "- visualización\n",
    "- filtrado\n",
    "- incluir en loc y iloc ejemplos temporales y booleanos (ej dfl.loc['20130102':'20130104'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links de interés\n",
    "- Datasets https://www.kaggle.com/datasets\n",
    "- Documentación de Pandas https://pandas.pydata.org/docs/index.html \n",
    "- Cookbook de pandas https://pandas.pydata.org/docs/user_guide/cookbook.html\n",
    "- Estructura y un par de cosas sobre data engineering https://apmonitor.com/pds/index.php/Main/DataPreparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import importantes y cargo pickles de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitanespiral/Documents/GitHub/data_science/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/capitanespiral/.cache/kagglehub/datasets/isathyam31/adult-income-prediction-classification/versions/1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "kagglehub.dataset_download(\"isathyam31/adult-income-prediction-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo pickles\n",
    "with open(\"df.pkl\",\"rb\") as file:\n",
    "    df=pickle.load(file)\n",
    "    \n",
    "with open(\"df_t.pkl\",\"rb\") as file:\n",
    "    df_t=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función más usada, lejos es `read_csv` de pandas, donde basta que demos el path del archivo y su nombre, y se leerá si no hay mayor problema. Por default, la primera fila se transforma en las columnas del dataframe, que podemos ver usando `dataframe.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/capitanespiral/Documents/GitHub/data_science\" #Aquí introducir tu path\n",
    "filename=\"data.csv\"\n",
    "\n",
    "df=pd.read_csv(f\"{path}/{filename}\")\n",
    "#Display entrega mucho mejor resultado que print para los dataframes!\n",
    "display(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Opciones más usadas de `read_csv`:\n",
    "- **sep o delimiter** &rarr; El separador de la data, usualmente se encuentra solo pero a veces es mejor darlo explícitamente. (en el caso que se confunda el identificador automático)\n",
    "- **header** &rarr; Número de fila que se toma como nombre de columnas y desde el cual comienza la data, por default, cero (inicio del .csv).\n",
    "- **skiprows** &rarr; Filas a saltar desde el inicio del archivo (indexeando desde cero, se puede entregar lista o tupla)\n",
    "- **skipfooter** &rarr; Filas a saltar desde el final del archivo.\n",
    "- **usecols** &rarr; Subset de columnas a usar (secuencia de números o nombres explícitos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la primera fila está mala, cambiamos el header\n",
    "df1=pd.read_csv(\"data_bad_first_row.csv\") #Salió pésimo\n",
    "df2=pd.read_csv(\"data_bad_first_row.csv\",header=1) #Mucho mejor\n",
    "\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la segunda está mala\n",
    "df3=pd.read_csv(\"data_bad_second_row.csv\") #Primer dato pésimo\n",
    "df4=pd.read_csv(\"data_bad_second_row.csv\",skiprows=[1],header=0) #Nos saltamos la segunda fila y conservamos el header\n",
    "\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionemos ciertas columnas no más\n",
    "df5=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[0,3]) #Puede ser con números, aquí la primera y la cuarta\n",
    "df6=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=range(4)) #Puede ser con iteradores, acá me entrega de la primera A la cuarta\n",
    "df7=pd.read_csv(\"data_bad_first_row.csv\",header=1,usecols=[\"age\",\"education\",\"workclass\"]) #Puede ser con los nombres explícitos\n",
    "\n",
    "display(df5)\n",
    "display(df6)\n",
    "display(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1,df2,df3,df4,df5,df6,df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de series de tiempo, hay que saber trabajar con `Timestamps`, `Datetime`, `Timedelta`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones generales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pd.to_datetime()** &rarr; Transforma lo que le entregues en un \"Datetime\", funciona aceptando varios formatos y si le entregas secuencias.\n",
    "- **pd.date_range()** &rarr; Para crear puntos en el tiempo equiespaceados, con un \"start\" un \"end\", posibilidad de \"periods\" o \"freq\"\n",
    "    - **freq** más comunes:\"y\" (años),\"m\" (meses),\"W\" (semana), \"B\" (business day), \"d\" (días), \"h\" (horas), \"min\" (minutos), \"s\" (segundos) Ojo que hay *infinitas* opciones! revisar en https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "- **df.resample().func()** &rarr; Entregando como variable una frecuencia, podemos \"resamplear\" según la función \"func\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datetime con varios formatos\n",
    "dt1=pd.to_datetime([\"13/1/2018\", np.datetime64(\"2018-01-13\"), datetime.datetime(2018, 1, 13)],dayfirst=True)\n",
    "print(\"dt1:\",dt1,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##date_range\n",
    "#Creando una lista de tiempo cada tres horas\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt2=pd.date_range(start=t1,end=t2,freq=\"3h\")\n",
    "print(\"dt2:\",dt2,\"\\n\")\n",
    "\n",
    "#Lo mismo pero con 15 minutos\n",
    "t1=\"1-1-2000\"\n",
    "t2=\"2000-3-10\"\n",
    "dt3=pd.date_range(start=t1,end=t2,freq=\"15min\")\n",
    "print(\"dt3:\",dt3,\"\\n\")\n",
    "\n",
    "#Si tengo periodos y frecuencia\n",
    "dt4=pd.date_range(start=\"2018-8-1\", periods=5, freq=\"2d\")\n",
    "print(\"dt4:\",dt4,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como usar el resampleo\n",
    "idx = pd.date_range(\"2018-01-01\", periods=10, freq=\"h\") #ojo que 1h = h\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(\"ts\",ts,\"\\n\",sep=\"\\n\")\n",
    "#Downsample (también muy usado el sum)\n",
    "ts_downsampled=ts.resample(\"2h\").mean() #LEJOS el más útil\n",
    "print(\"ts_downsampled\",ts_downsampled,\"\\n\",sep=\"\\n\")\n",
    "#upsample (también muy usado bfill)\n",
    "ts_upsampled=ts.resample(\"30min\").ffill() #Sería interesante, acá interpolar\n",
    "print(\"ts_upsampled\",ts_upsampled,\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt1,dt2,dt3,dt4,idx,ts,ts_upsampled,ts_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora trabajemos con data de verdad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=pd.read_csv(\"biomet1.csv\",skiprows=[1],header=0) #Tenemos caso de segunda linea sin sentido\n",
    "df_t[\"time_t\"]=pd.to_datetime(df_t['date']+\" \"+df_t['time']) #Lo guardamos en una nueva columna\n",
    "display(df_t)\n",
    "print(\"\\nLa columna nueva:\",df_t[\"time_t\"],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos servirá ahora\n",
    "- **datetime.min() y .max()** &rarr; Evidente\n",
    "- **datetimeindex.atributos** &rarr; nos permite acceder a muchas funciones de tiempo como \"hour\",\"day\",\"minute\",\"second\",\"dayofyear\", \"strftime\", entre otras (si es una serie, no un índice, agregar dt). La totalidad de atributos y métodos en https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html. La totalidad de formatos para \"strftime\" en https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos acceder a propiedades o métodos específicos de un objeto tipo \"datetime\" usando el \"dt\"\n",
    "print(\"Solo el año:\",df_t[\"time_t\"].dt.year,\"\\n\",sep=\"\\n\")\n",
    "print(\"Cambio el formato:\",df_t[\"time_t\"].dt.strftime(\"%Y  /   %m   /  %d\"),\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fijamos un nuevo índice\n",
    "df_t=df_t.set_index(\"time_t\") #Esto \"traslada\" la columna \"time_t\" (ya no existe como columna) - Y pasa a ser datetimeindex\n",
    "df_t=df_t.drop(columns = [\"date\",\"time\"]) #Boto las columnas que ya no necesito\n",
    "display(df_t)\n",
    "print(\"Y el nuevo índice:\")\n",
    "print(df_t.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al fijarlo como índice, ahora podemos accesar simplemente con \".atributo\"\n",
    "display(df_t)\n",
    "print(\"Solo el día:\",df_t.index.day,\"\\n\",sep=\"\\n\")\n",
    "print(\"Solo el día juliano:\",df_t.index.dayofyear,\"\\n\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos notar que hay vaciós en la data, en específico 3!\n",
    "fig,ax=plt.subplots(figsize=(16,10))\n",
    "ax.scatter(df_t.index,df_t.index,s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora cubrimos todo el espacio\n",
    "ti=df_t.index.min()\n",
    "tf=df_t.index.max()\n",
    "time_total=pd.date_range(start=ti,end=tf,freq=\"30min\")\n",
    "df_t=df_t.reindex(time_total) #Esta función redefine el índice, conservando datos y agregando nans si el nuevo índice coincide con el anterior o si no existe (para cada fila!)\n",
    "display(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se rellenó\n",
    "fig,ax=plt.subplots(figsize=(16,10))\n",
    "ax.scatter(df_t.index,df_t.index,s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamos como pickle los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El primer dataframe\n",
    "with open('df.pkl',\"wb\") as file:\n",
    "    pickle.dump(df,file)\n",
    "\n",
    "#El dataframe de serie de tiempo\n",
    "with open('df_t.pkl',\"wb\") as file:\n",
    "    pickle.dump(df_t,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See data and basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entender que *pandas* tiene dos grandes tipos de objetos: `Series`y `DataFrame`. El primero es como un \"vector\" (unidimensional) y el segundo está compuesto por varias `Series`, siendo como una \"matriz\". Y cada uno siempre tiene asociado su `Index`, que puede ser numérico o de cualquier naturaleza (uno común, temporal).\n",
    "\n",
    "La forma básica de indexar cada tipo tiene distintos resultados:\n",
    "- **Series[label]** &rarr; Dará un valor escalar en tal posición acorde al `Index`.\n",
    "- **DataFrame[colname]** &rarr; Dará una *Serie* correspondiente a tal nombre de columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Dataframe**\n",
      "Edad\n",
      "0        39\n",
      "1        50\n",
      "2        38\n",
      "3        53\n",
      "4        28\n",
      "         ..\n",
      "32556    27\n",
      "32557    40\n",
      "32558    58\n",
      "32559    22\n",
      "32560    52\n",
      "Name: age, Length: 32561, dtype: int64\n",
      "\n",
      "\n",
      "Tercer valor: 38 \n",
      "\n",
      "**Dataframe temporal**\n",
      "Calor sensible\n",
      "2014-01-01 00:30:00     2.10820\n",
      "2014-01-01 01:00:00    -4.62751\n",
      "2014-01-01 01:30:00   -25.06920\n",
      "2014-01-01 02:00:00   -19.36180\n",
      "2014-01-01 02:30:00    -2.52581\n",
      "                         ...   \n",
      "2018-02-08 21:00:00   -10.19220\n",
      "2018-02-08 21:30:00   -11.88980\n",
      "2018-02-08 22:00:00   -46.52960\n",
      "2018-02-08 22:30:00   -16.58690\n",
      "2018-02-08 23:00:00   -22.25020\n",
      "Freq: 30min, Name: H, Length: 71998, dtype: float64\n",
      "\n",
      "\n",
      "Tercer valor indexando con 'int': -25.0692\n",
      "Tercer valor indexando con un 'label' del 'index': -25.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30198/3667856936.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Tercer valor indexando con 'int':\",df_t[\"H\"][2]) #Obtengo el tercer valor -> Notar advertencia de pandas!\n"
     ]
    }
   ],
   "source": [
    "#Accedo a una columna, me entrega a una serie, y despues a un elemento en específico\n",
    "print(\"**Dataframe**\")\n",
    "print(\"Edad\",df[\"age\"],\"\\n\",sep=\"\\n\")\n",
    "print(\"Tercer valor:\",df[\"age\"][2],\"\\n\") #df[\"age\"] es una serie, entonces df[\"age\"][2] es el valor asociado al indice 2 de la serie\n",
    "\n",
    "#Si el índice no es numérico, esto igual se puede hacer, pero se recomienda indexar acorde al índice\n",
    "print(\"**Dataframe temporal**\")\n",
    "print(\"Calor sensible\",df_t[\"H\"],\"\\n\",sep=\"\\n\") #Notar que el índice es temporal\n",
    "print(\"Tercer valor indexando con 'int':\",df_t[\"H\"][2]) #Obtengo el tercer valor -> Notar advertencia de pandas!\n",
    "print(\"Tercer valor indexando con un 'label' del 'index':\",df_t[\"H\"][\"2014-01-01 01:30:00\"]) #Lo mismo pero con el tiempo, engorroso pero preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre podemos acceder a **varios valores** de una *serie* (con indexación típica de python) o **varias columnas** en un *dataframe* (agregando un nuevo []:). Notar que esto último entrega un nuevo `DataFrame` que no permite indexación \"típica\" de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>11th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    education\n",
       "0       39    Bachelors\n",
       "1       50    Bachelors\n",
       "2       38      HS-grad\n",
       "3       53         11th\n",
       "4       28    Bachelors\n",
       "...    ...          ...\n",
       "32556   27   Assoc-acdm\n",
       "32557   40      HS-grad\n",
       "32558   58      HS-grad\n",
       "32559   22      HS-grad\n",
       "32560   52      HS-grad\n",
       "\n",
       "[32561 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Del segundo al quinto valor de una columna:\n",
      "1    50\n",
      "2    38\n",
      "3    53\n",
      "4    28\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display(df[[\"age\",\"education\"]])\n",
    "#display(df[[\"age\",\"education\"]][1:5]) #Esto tira error\n",
    "print(\"Del segundo al quinto valor de una columna:\",df[\"age\"][1:5],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También usando slices de enteros en una *serie* o *dataframe* (en este caso se accesarán filas, no columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexado clásico de python sobre una serie\n",
    "print(\"Del primer al quinto dato:\",df[\"age\"][:5],\"\\n\",sep=\"\\n\") \n",
    "print(\"Los datos pares:\",df[\"age\"][::2],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "#Indexado clásico de python sobre un dataframe\n",
    "print(\"\\nDel primer al quinto dato:\")\n",
    "display(df_t[:5]) \n",
    "print(\"\\nLos datos dados vuelta:\")\n",
    "display(df_t[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para indexar también se tienen los métodos `.loc` y `.iloc`(para *series* y *dataframes*)\n",
    "1. `.loc` &rarr; trabaja con labels del índice o con arreglos booleanos.\n",
    "2. `.iloc` &rarr; trabaja con posisiones con enteros (desde 0 a -1) o con arreglos booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df.drop([1]) #Boto la segunda fila\n",
    "display(df_temp)\n",
    "\n",
    "print(\"Con loc\",df_temp.loc[2],\"\\n\",sep=\"\\n\") #Aquí 2 es interpretado como \"label\", será la segunda fila\n",
    "\n",
    "print(\"Con loc\",df_temp.iloc[2],\"\\n\",sep=\"\\n\") #Aquí como entero, será la tercera fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando listas de elementos\n",
    "print(\"Usando listas:\")\n",
    "\n",
    "display(df_temp.loc[[0,3,5]]) #El label 0, 3, 5\n",
    "\n",
    "display(df_temp.iloc[[0,3,5]]) #Las posiciones asociados (otro label)\n",
    "\n",
    "#También usando \"slices\"\n",
    "print(\"\\nUsando slices ahora:\")\n",
    "\n",
    "display(df_temp.loc[0:5])\n",
    "\n",
    "display(df_temp.iloc[0:5])\n",
    "\n",
    "print(\"En este caso funcionan igual por la naturaleza de este índice. NOTAR que se incluye el PRINCIPIO Y EL FINAL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas loc\n",
    "print(\"Slice y columna - loc\",df_temp.loc[2:9,\"age\"],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - loc\")\n",
    "display(df_temp.loc[2:9,\"age\":\"sex\"])\n",
    "\n",
    "print(\"\\nFilas y columnas - loc\")\n",
    "display(df_temp.loc[[3,5,7],[\"age\",\"country\",\"race\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclando filas y columnas iloc\n",
    "\n",
    "print(\"Slice y columna - iloc\",df_temp.iloc[2:9,0],\"\\n\",sep=\"\\n\")\n",
    "\n",
    "print(\"Slice y slice - iloc\")\n",
    "display(df_temp.iloc[2:9,0:7])\n",
    "\n",
    "print(\"\\nFilas y columnas - iloc\")\n",
    "display(df_temp.iloc[[3,5,7],[0,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una serie de funciones que nos permiten visualizar la data. Dentro de las más básicas:\n",
    "- **df.head(n)** &rarr; nos permite ver las primeras \"n\" filas (sin n, por default 5), funciona para `Series` y `DataFrame`.\n",
    "- **df.tail(n)** &rarr; nos permite ver las últimas \"n\" filas (lo mismo), funciona para `Series` y `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para dataframes\n",
    "display(df.head())\n",
    "display(df.head(10))\n",
    "\n",
    "#Para una serie\n",
    "print(df[\"age\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.tail())\n",
    "\n",
    "display(df[\"workclass\"].tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
